
# ðŸ©ºÂ Handling Missing Values in Python (Pandas)  
*Last updatedÂ 2025-07-01*  

> **Goal:** Learn *why* data goes missing, *how* to diagnose it, and several handsâ€‘on strategies to fix it â€“ using the Titanic dataset as practice.

---

## 1Â Â Why Missing Values Matter  

Realâ€‘world datasets are almost **never** complete â€“ sensors fail, survey questions are skipped, log files cut shortâ€¦  
Ignoring the problem can:  

* break model training (`ValueError: Input contains NaN`)  
* bias statistics (means, correlations)  
* waste information if you drop too much data  

---

## 2Â Â Mechanisms of Missingness  

| Acronym | Name | What it means | Example |
|---------|------|---------------|---------|
| **MCAR** | Missing CompletelyÂ AtÂ Random | â€œAccidentalâ€ âœ¨ â€” missingness is unrelated to *any* variable (observed or hidden). | Typos during data entry, corrupt sensor packets |
| **MAR** | MissingÂ AtÂ Random | Missingness depends **only on other observed variables**. | Survey: income left blank more often by younger respondents |
| **MNAR** | MissingÂ NotÂ AtÂ Random | Missingness depends on the **missing value itself** (or unobserved factors). | Employees unsatisfied with pay refuse to report salary |

> *Why care?* The mechanism determines which imputation methods are statistically sound.  
For this tutorial weâ€™ll focus on practical remedies used dayâ€‘toâ€‘day.

---

## 3Â Â Imports & Dataset  

```python
import pandas as pd
import numpy as np
import seaborn as sns              # statistical plotting
import matplotlib.pyplot as plt    # base plotting
```

```python
# Titanic passenger data â€“ convenient for demos
df = sns.load_dataset("titanic")
df.head()
```

> **`sns.load_dataset`** grabs small, clean datasets that ship with Seaborn (great for demos).

---

## 4Â Â Diagnosing Missingness  

### 4.1Â Quick counts  

```python
df.isna().sum()         # same as .isnull()
```

*Why `.isna()`?* It returns a **boolean mask** (True=missing), so chaining `.sum()` counts True values down each column.

### 4.2Â Visual overview *(optional)*  

```python
sns.heatmap(df.isna(), cbar=False)
plt.title("Missingâ€‘value matrix")
plt.show()
```

*(Add the plot to your notebook for an immediate sense of patterns â€“ dark bands signal systematic gaps.)*

---

## 5Â Â StrategyÂ 0 â€“ Deletion (a.k.a. â€œlistwiseÂ deletionâ€)  

```python
df_drop_rows = df.dropna()          # drop rows with *any* NaN
df_drop_cols = df.dropna(axis=1)    # drop columns with *any* NaN
```

| Pros | Cons |
|------|------|
| Fast, no assumptions | Can throw away tons of data & introduce bias |

> **Rule of thumb:** Only drop a column if the *majority* of its entries are missing (e.g. `deck` in Titanic has 77% NaNs).

---

## 6Â Â StrategyÂ 1 â€“ Mean / Median Imputation (Numeric)  

### 6.1Â Mean (good for roughly symmetric distributions)

```python
age_mean = df["age"].mean()
df["age_imp_mean"] = df["age"].fillna(age_mean)
```

*Functions explained*  
* **`.mean()`** â€“ arithmetic average (skips NaNs automatically).  
* **`.fillna(value)`** â€“ returns a new Series where NaNs are replaced.

### 6.2Â Median (robust to outliers / skew)  

```python
age_median = df["age"].median()
df["age_imp_median"] = df["age"].fillna(age_median)
```

> **Tip:** Use `df["age"].hist()` or `sns.histplot` to inspect distribution shape and decide between mean / median.

---

## 7Â Â StrategyÂ 2 â€“ Mode Imputation (Categorical)  

```python
emb_mode = df["embarked"].mode()[0]   # `.mode()` returns Series
df["embarked_imp"] = df["embarked"].fillna(emb_mode)
```

*Why mode?* Replacing with the **most frequent** class keeps category proportions close to original.

---

## 8Â Â StrategyÂ 3 â€“ Random Sample Imputation  

Keeps the *original distribution* by randomly sampling observed values.

```python
def random_sample_impute(series, seed=None):
    np.random.seed(seed)
    miss_mask = series.isna()
    n_missing = miss_mask.sum()
    samples = np.random.choice(series.dropna(), n_missing, replace=True)
    series.loc[miss_mask] = samples
    return series

df["age_imp_rand"] = random_sample_impute(df["age"].copy(), seed=42)
```

---

## 9Â Â Bonus â€“ Scikitâ€‘Learn Imputers  

| Imputer | When to use |
|---------|-------------|
| `SimpleImputer(strategy="mean/median/most_frequent")` | Same as manual fill but integrates into `Pipeline` |
| `KNNImputer` | Fills NaNs with values from nearestâ€‘neighbour rows |
| `IterativeImputer` | Multivariate regression (MICE) â€“ more advanced |

Small example:

```python
from sklearn.impute import SimpleImputer

num_imputer = SimpleImputer(strategy="median")
df[["age"]] = num_imputer.fit_transform(df[["age"]])
```

---

## 10Â Â Putting It All Together â€“ MiniÂ Workflow  

```python
# 1. Drop columns with >70â€¯% missing
threshold = len(df) * 0.7
df = df.loc[:, df.isna().sum() < threshold]

# 2. Impute numeric & categorical separately
num_cols  = df.select_dtypes("number").columns
cat_cols  = df.select_dtypes("object").columns

df[num_cols] = df[num_cols].apply(
    lambda col: col.fillna(col.median())
)
df[cat_cols] = df[cat_cols].apply(
    lambda col: col.fillna(col.mode()[0])
)
```

---

## 11Â Â Key Takeâ€‘Aways  

* Always **profile** missingness first â€“ size & pattern drive the fix.  
* Deleting is easiest but often costly.  
* Mean/median/mode imputation is quick, but injects bias â€“ keep in mind for downstream modelling.  
* For production pipelines use **`sklearn` imputers** inside a `Pipeline` so the same logic applies to training & new data.  

---

### References & Further Reading  

* Little & Rubin â€“ *Statistical Analysis with Missing Data*  
* scikitâ€‘learn documentation: [Imputation](https://scikit-learn.org/stable/modules/impute.html)  

---

*Happy cleaning!* ðŸ§½
